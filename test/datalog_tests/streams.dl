/* Test "stream" relations.  They should take no memory.  */

import json
import hashset

typedef Object = Object {
    field: u128
}

/* Raw JSON chunks. */
input stream Chunk(json: string)

/* Output an error message for each chunk that failed to parse. */
output stream ChunkParseError(err: string)
ChunkParseError(err) :- ParsedChunk(Err{err}).

/* Contains the result of parsing a chunk. */
stream ParsedChunk(data: Result<Object, string>)

ParsedChunk(from_json_string(json)) :- Chunk(json).

/* Successfully parsed chunks are stored in the Objects
 * relation. */
stream Objects(chunk: Object)
Objects(objs) :- ParsedChunk(Ok{objs}).

/* Convert chunks back to JSON. */
output stream CompressedChunk(json: string)
CompressedChunk(json) :-
    Objects(objs),
    Ok{var json} = to_json_string(objs).

/* Test streaming joins. */

// "Persistent" key-value store.
input relation ZipCodes(zip: u32, city: string)

// Stream of ephemeral queries.
input stream ZipQueries(zip: u32)

// Relation-stream semijoin.
output stream ZipResultsRS(zip: u32, city: string)
ZipResultsRS(zip, city) :-
    ZipCodes(zip, city),
    ZipQueries(zip).

// Stream-relation semijoin.
output stream ZipResultsSR(zip: u32, city: string)
ZipResultsSR(zip, city) :-
    ZipQueries(zip),
    ZipCodes(zip, city).

// Full join

// Stream of ephemeral queries.
input stream ZipQueries2(zip: u32, distance: u32)

// Relation-stream join.
output stream ZipResults2RS(zip: u32, city: string, distance: u32)
ZipResults2RS(zip, city, distance) :-
    ZipCodes(zip, city),
    ZipQueries2(zip, distance).

// Filter before and after join.
output stream ZipResults2RSFiltered(zip: u32, city: string, distance: u32, descr: string)
ZipResults2RSFiltered(zip, city, distance, descr) :-
    ZipCodes(zip, city),
    city != "Los Altos",
    var descr1 = "${zip} is in ${city}",
    ZipQueries2(zip, distance),
    var descr = "${descr1}, ${distance} miles away".

// Stream-relation join.
output stream ZipResults2SR(zip: u32, city: string, distance: u32)
ZipResults2SR(zip, city, distance) :-
    ZipQueries2(zip, distance),
    ZipCodes(zip, city).

// Filter before and after join.
output stream ZipResults2SRFiltered(zip: u32, city: string, distance: u32, descr: string)
ZipResults2SRFiltered(zip, city, distance, descr) :-
    ZipQueries2(zip, distance),
    distance > 4,
    var descr1 = "${zip}",
    ZipCodes(zip, city),
    var descr = "${descr1} is in ${city}, ${distance} miles away".

// Relation-stream-relation sandwich.
output stream ZipResults2RSRFiltered(zip: u32, city: string, distance: u32, descr: string)
ZipResults2RSRFiltered(zip, city, distance, descr) :-
    ZipCodes(zip, city),
    var descr1 = "${zip} is in ${city}",
    ZipQueries2(zip, distance),
    distance > 4,
    var descr2 = "${distance} miles away",
    ZipCodes(zip, city),
    var descr = "${descr1}, ${descr2}".

/*
 * Scale test
 */

input relation KVStore(k: usize, v: string)

// Streaming queries.
input stream KVStreamQuery(k: usize)
output stream KVStreamResponse(k: usize, v: string)

KVStreamResponse(k, v) :-
    KVStreamQuery(k),
    KVStore(k, v).

// Relational queries.
input relation KVRelQuery(k: usize)
output relation KVRelResponse(k: usize, v: string)

KVRelResponse(k, v) :-
    KVRelQuery(k),
    KVStore(k, v).

// Stream aggregation

input stream StreamToGroup(k: string, v: usize)
output stream StreamGroups(k: string, vs: Vec<usize>)

StreamGroups(k, vs) :-
    StreamToGroup(k, v),
    var vs = v.group_by(k).to_vec().

// Stream fold
output relation StreamOfSums(k: string, s: usize)

relation StreamFold(k: string, v: usize)

StreamFold(k, v) :- StreamToGroup'(k, v).
StreamFold(k, s) :- StreamOfSums-1(k, s).

StreamOfSums(k, s) :-
    StreamFold(k, v),
    var s = v.group_by(k).group_sum().

// Stream fold with enable/disable control

output relation ControlledStreamOfSums(k: string, s: usize)
input relation EnableK(k: string)

relation ControlledStreamFold(k: string, v: usize)

ControlledStreamFold(k, v) :- StreamToGroup'(k, v).
ControlledStreamFold(k, s) :- ControlledStreamOfSums-1(k, s),
                              EnableK(k). // Test that joins work for delayed relations.

ControlledStreamOfSums(k, s) :-
    ControlledStreamFold(k, v),
    var s = v.group_by(k).group_sum(),
    EnableK(k).

/* Compute sum, average, and unique values aggregates over the same stream. */

// Current time in seconds.
typedef STime = usize

input relation CurrentTime(t: STime)
// primary key, so we can `insert_or_update` to overwrite the timestamp.
primary key (x) ()

output relation TimeWindow(start: STime, end: STime)

// Track current and previous windows
TimeWindow(start, end) :-
    CurrentTime(t),
    var start = t - t % 5,
    var end = start + 5.

TimeWindow(start, end) :-
    CurrentTime(t),
    var start = t - t % 5 - 5,
    var end = start + 5.

input stream Data(ts: STime, value: usize)

// Sum
output relation DataSum(window: TimeWindow, sum: usize)
relation DataSumFold(window: TimeWindow, value: usize)

DataSumFold(window, value) :-
    Data'(ts, value),
    window in TimeWindow(start, end),
    ts >= start,
    ts < end.

// previous aggregate
DataSumFold(window, sum) :-
    DataSum-1(window, sum),
    TimeWindow[window].

DataSum(window, sum) :-
    DataSumFold(window, value),
    var sum = value.group_by(window).wsum().

function wsum(g: Group<'K, usize>): usize {
    var s = 0;
    for ((x, w) in g) {
        s = s + x * (w as usize)
    };
    s
}

// Average
relation DataAvgInner(window: TimeWindow, avg: (/*sum*/usize, /*count*/usize))
output relation DataAvg(window: TimeWindow, avg: usize)

DataAvg(window, sum/cnt) :- DataAvgInner(window, (sum, cnt)).

relation DataAvgFold(window: TimeWindow, avg: (usize, usize))

DataAvgFold(window, (value, 1)) :-
    Data'(ts, value),
    window in TimeWindow(start, end),
    ts >= start,
    ts < end.

DataAvgFold(window, avg) :-
    DataAvgInner-1(window, avg),
    TimeWindow[window].

DataAvgInner(window, avg) :-
    DataAvgFold(window, (sum,cnt)),
    var grp = (sum, cnt).group_by(window),
    var avg = {
        var sum = 0;
        var cnt = 0;
        for ((x, w) in grp) {
            sum = sum + x.0 * (w as usize);
            cnt = cnt + x.1 * (w as usize);
        };
        (sum, cnt)
    }.

// Unique

output relation DataUnique(window: TimeWindow, unique_vals: Set<usize>)

relation DataUniqueFold(window: TimeWindow, unique_vals: Set<usize>)

DataUniqueFold(window, set_singleton(value)) :-
    Data'(ts, value),
    window in TimeWindow(start, end),
    ts >= start,
    ts < end.

DataUniqueFold(window, unique) :-
    DataUnique-1(window, unique),
    TimeWindow[window].

DataUnique(window, unique) :-
    DataUniqueFold(window, unique_vals),
    var unique = unique_vals.group_by(window).group_set_unions().

/* Count the number of unique values in a stream using regular sets
 * and immutable HashSet. */

typedef user_id = u128

/* Regular sets */

input stream UserSession1(user: user_id)

stream UniqueUsersFold1(users: Set<user_id>)
UniqueUsersFold1(set_singleton(user)) :-
    UserSession1(user).

UniqueUsersFold1(old_users) :-
    UniqueUsers1-1(old_users).

stream UniqueUsers1(users: Set<user_id>)

UniqueUsers1(all_users) :-
    UniqueUsersFold1(users),
    var all_users = users.group_by(()).union().

output stream UniqueUserCount1(num_unique: usize)
UniqueUserCount1(users.size()) :- UniqueUsers1(users).

/* Implementation using immutable sets. */
input stream UserSession2(user: user_id)

stream UniqueUsersFold2(users: HashSet<user_id>)
UniqueUsersFold2(hashset_singleton(user)) :-
    UserSession2(user).

UniqueUsersFold2(old_users) :-
    UniqueUsers2-1(old_users).

stream UniqueUsers2(users: HashSet<user_id>)

UniqueUsers2(all_users) :-
    UniqueUsersFold2(users),
    var all_users = users.group_by(()).union().

output stream UniqueUserCount2(num_unique: usize)
UniqueUserCount2(users.size()) :- UniqueUsers2(users).
