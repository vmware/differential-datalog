mod c_api;

#[cfg(feature = "c_api")]
pub use c_api::*;

use std::ffi;
use std::fs;
use std::io;
use std::iter;
use std::mem;
use std::os::raw;

#[cfg(unix)]
use std::os::unix::io::{FromRawFd, IntoRawFd, RawFd};
#[cfg(windows)]
use std::os::windows::io::{FromRawHandle, IntoRawHandle, RawHandle};

use std::ptr;
use std::slice;
use std::sync::{Arc, Mutex};

use differential_datalog::ddval::*;
use differential_datalog::program::*;
use differential_datalog::record::{IntoRecord, Record};
use differential_datalog::replay;
use differential_datalog::Callback;
use differential_datalog::CommandRecorder;
use differential_datalog::DeltaMap;
use differential_datalog::{
    D3log, D3logLocationId, DDlog, DDlogDump, DDlogDynamic, DDlogInventory, DDlogProfiling,
};
use std::collections::BTreeMap;
use std::collections::BTreeSet;

use super::update_handler::*;
use super::*;

/* FlatBuffers bindings generated by `ddlog` */
#[cfg(feature = "flatbuf")]
use super::flatbuf;

#[cfg(feature = "flatbuf")]
use super::flatbuf::FromFlatBuffer;

// TODO: Move HDDlog into the differential_datalog crate.
#[derive(Debug)]
pub struct HDDlog {
    pub prog: Mutex<RunningProgram>,
    pub update_handler: Box<dyn IMTUpdateHandler>,
    pub db: Option<Arc<Mutex<DeltaMap<DDValue>>>>,
    pub deltadb: Arc<Mutex<Option<DeltaMap<DDValue>>>>,
    pub print_err: Option<extern "C" fn(msg: *const raw::c_char)>,
    /// When set, all commands sent to the program are recorded in
    /// the specified `.dat` file so that they can be replayed later.
    pub command_recorder: Option<CommandRecorder<fs::File, Box<dyn DDlogInventory + Send + Sync>>>,
}

impl HDDlog {
    pub fn run(workers: usize, do_store: bool) -> Result<(Self, DeltaMap<DDValue>), String>
    where
        Self: Sized,
    {
        Self::do_run(workers, do_store, None)
    }

    pub fn print_err(f: Option<extern "C" fn(msg: *const raw::c_char)>, msg: &str) {
        match f {
            None => eprintln!("{}", msg),
            Some(f) => f(ffi::CString::new(msg).unwrap().into_raw()),
        }
    }

    pub fn eprintln(&self, msg: &str) {
        Self::print_err(self.print_err, msg)
    }

    pub fn record_commands(&mut self, file: &mut Option<fs::File>) {
        let mut old_recorder = None;
        mem::swap(&mut self.command_recorder, &mut old_recorder);
        let mut old_file = old_recorder.map(|r| r.release_writer());
        mem::swap(file, &mut old_file);

        match old_file {
            None => self.command_recorder = None,
            Some(f) => self.command_recorder = Some(CommandRecorder::new(f, Box::new(Inventory))),
        }
    }

    /// Apply a set of updates directly from the flatbuffer
    /// representation
    #[cfg(feature = "flatbuf")]
    fn apply_updates_from_flatbuf(&self, buf: &[u8]) -> Result<(), String> {
        let cmditer = flatbuf::updates_from_flatbuf(buf)?;
        let upds: Result<Vec<Update<DDValue>>, String> = cmditer
            .map(|cmd| flatbuf::DDValueUpdate::from_flatbuf(cmd).map(|x| x.0))
            .collect();
        self.apply_updates(&mut upds?.into_iter())
    }

    /// Similar to `query_index`, but extracts query from a flatbuffer.
    #[cfg(feature = "flatbuf")]
    fn query_index_from_flatbuf(&self, buf: &[u8]) -> Result<BTreeSet<DDValue>, String> {
        let (idxid, key) = flatbuf::query_from_flatbuf(buf)?;
        self.query_index(idxid, key)
    }
}

pub struct Inventory;

impl DDlogInventory for Inventory {
    fn get_table_id(&self, tname: &str) -> Result<RelId, String> {
        Relations::try_from(tname)
            .map_err(|()| format!("unknown relation {}", tname))
            .map(|rel| rel as RelId)
    }

    fn get_table_name(&self, tid: RelId) -> Result<&'static str, String> {
        relid2name(tid).ok_or_else(|| format!("unknown relation {}", tid))
    }

    #[cfg(feature = "c_api")]
    fn get_table_cname(&self, tid: RelId) -> Result<&'static ffi::CStr, String> {
        relid2cname(tid).ok_or_else(|| format!("unknown relation {}", tid))
    }

    fn get_index_id(&self, iname: &str) -> Result<IdxId, String> {
        Indexes::try_from(iname)
            .map_err(|()| format!("unknown index {}", iname))
            .map(|idx| idx as IdxId)
    }

    fn get_index_name(&self, iid: IdxId) -> Result<&'static str, String> {
        indexid2name(iid).ok_or_else(|| format!("unknown index {}", iid))
    }

    #[cfg(feature = "c_api")]
    fn get_index_cname(&self, iid: IdxId) -> Result<&'static ffi::CStr, String> {
        indexid2cname(iid).ok_or_else(|| format!("unknown index {}", iid))
    }
}

impl DDlogInventory for HDDlog {
    fn get_table_id(&self, tname: &str) -> Result<RelId, String> {
        Inventory.get_table_id(tname)
    }

    fn get_table_name(&self, tid: RelId) -> Result<&'static str, String> {
        Inventory.get_table_name(tid)
    }

    #[cfg(feature = "c_api")]
    fn get_table_cname(&self, tid: RelId) -> Result<&'static ffi::CStr, String> {
        Inventory.get_table_cname(tid)
    }

    fn get_index_id(&self, iname: &str) -> Result<IdxId, String> {
        Inventory.get_index_id(iname)
    }

    fn get_index_name(&self, iid: IdxId) -> Result<&'static str, String> {
        Inventory.get_index_name(iid)
    }

    #[cfg(feature = "c_api")]
    fn get_index_cname(&self, iid: IdxId) -> Result<&'static ffi::CStr, String> {
        Inventory.get_index_cname(iid)
    }
}
impl DDlogDump for HDDlog {
    fn dump_input_snapshot(&self, w: &mut dyn io::Write) -> io::Result<()> {
        for (rel, relname) in INPUT_RELIDMAP.iter() {
            let prog = self.prog.lock().unwrap();
            match prog.get_input_relation_data(*rel as RelId) {
                Ok(valset) => {
                    for v in valset.iter() {
                        replay::record_insert(w, relname, v)?;
                        writeln!(w, ",")?;
                    }
                }
                _ => match prog.get_input_relation_index(*rel as RelId) {
                    Ok(ivalset) => {
                        for v in ivalset.values() {
                            replay::record_insert(w, relname, v)?;
                            writeln!(w, ",")?;
                        }
                    }
                    _ => match prog.get_input_multiset_data(*rel as RelId) {
                        Ok(ivalmset) => {
                            for (v, weight) in ivalmset.iter() {
                                if *weight >= 0 {
                                    for _ in 0..*weight {
                                        replay::record_insert(w, relname, v)?;
                                        writeln!(w, ",")?;
                                    }
                                } else {
                                    for _ in 0..(-*weight) {
                                        replay::record_delete(w, relname, v)?;
                                        writeln!(w, ",")?;
                                    }
                                }
                            }
                        }
                        _ => {
                            panic!("Unknown input relation {:?} in dump_input_snapshot", rel);
                        }
                    },
                },
            }
        }
        Ok(())
    }

    fn dump_table(
        &self,
        table: RelId,
        cb: Option<&dyn Fn(&record::Record, isize) -> bool>,
    ) -> Result<(), String> {
        self.record_command(|r| r.dump_table(table, None));
        if let Some(ref db) = self.db {
            HDDlog::db_dump_table(&mut db.lock().unwrap(), table, cb);
            Ok(())
        } else {
            Err(
                "cannot dump table: ddlog_run() was invoked with do_store flag set to false"
                    .to_string(),
            )
        }
    }
}

impl DDlogProfiling for HDDlog {
    fn enable_cpu_profiling(&self, enable: bool) -> Result<(), String> {
        self.record_command(|r| r.enable_cpu_profiling(enable));
        self.prog.lock().unwrap().enable_cpu_profiling(enable);
        Ok(())
    }

    fn enable_timely_profiling(&self, enable: bool) -> Result<(), String> {
        self.record_command(|r| r.enable_timely_profiling(enable));
        self.prog.lock().unwrap().enable_timely_profiling(enable);
        Ok(())
    }

    fn profile(&self) -> Result<String, String> {
        self.record_command(|r| r.profile());
        let rprog = self.prog.lock().unwrap();
        let profile = rprog
            .profile
            .as_ref()
            .map(|profile| profile.lock().unwrap().to_string())
            .unwrap_or_else(String::new);

        Ok(profile)
    }
}

impl DDlogDynamic for HDDlog {
    fn transaction_start(&self) -> Result<(), String> {
        self.record_command(|r| r.transaction_start());
        self.prog.lock().unwrap().transaction_start()
    }

    fn transaction_commit(&self) -> Result<(), String> {
        self.record_command(|r| r.transaction_commit());
        self.update_handler.before_commit();

        match (self.prog.lock().unwrap().transaction_commit()) {
            Ok(()) => {
                self.update_handler.after_commit(true);
                Ok(())
            }
            Err(e) => {
                self.update_handler.after_commit(false);
                Err(e)
            }
        }
    }

    fn transaction_commit_dump_changes_dynamic(
        &self,
    ) -> Result<BTreeMap<RelId, Vec<(Record, isize)>>, String> {
        self.record_command(|r| r.transaction_commit_dump_changes_dynamic());
        Ok(self
            .transaction_commit_dump_changes()?
            .into_iter()
            .map(|(relid, delta_typed)| {
                let delta_dynamic: Vec<(Record, isize)> = delta_typed
                    .into_iter()
                    .map(|(v, w)| (v.into_record(), w))
                    .collect();
                (relid, delta_dynamic)
            })
            .collect())
    }

    fn transaction_rollback(&self) -> Result<(), String> {
        self.record_command(|r| r.transaction_rollback());
        self.prog.lock().unwrap().transaction_rollback()
    }

    fn clear_relation(&self, table: RelId) -> Result<(), String> {
        self.record_command(|r| r.clear_relation(table));
        self.prog.lock().unwrap().clear_relation(table)
    }

    fn apply_updates_dynamic(&self, upds: &mut dyn Iterator<Item = UpdCmd>) -> Result<(), String> {
        let mut conversion_err = false;
        let mut msg: Option<String> = None;

        // Iterate through all updates, but only feed them to `apply_updates` until we reach
        // the first invalid command.
        // XXX: We must iterate till the end of `upds`, as `ddlog_apply_updates` relies on this to
        // deallocate all commands.
        let convert = |u: UpdCmd| {
            if conversion_err {
                None
            } else {
                match updcmd2upd(&u) {
                    Ok(u) => Some(u),
                    Err(e) => {
                        conversion_err = true;
                        msg = Some(format!("invalid command {:?}: {}", u, e));
                        None
                    }
                }
            }
        };

        let res = if self.command_recorder.is_some() {
            let update_vec: Vec<_> = upds.collect();
            self.record_command(|r| r.apply_updates_dynamic(&mut update_vec.iter().cloned()));

            self.apply_updates(&mut update_vec.into_iter().flat_map(convert)
                as &mut dyn Iterator<Item = Update<DDValue>>)
        } else {
            self.apply_updates(
                &mut upds.flat_map(convert) as &mut dyn Iterator<Item = Update<DDValue>>
            )
        };

        match msg {
            Some(e) => Err(e),
            None => res,
        }
    }

    fn query_index_dynamic(&self, index: IdxId, key: &Record) -> Result<Vec<Record>, String> {
        self.record_command(|r| r.query_index_dynamic(index, key));
        let idx = Indexes::try_from(index).map_err(|()| format!("unknown index {}", index))?;
        let k = idxkey_from_record(idx, key)?;
        Ok(self
            .query_index(index, k)?
            .into_iter()
            .map(|v| v.into_record())
            .collect())
    }

    fn dump_index_dynamic(&self, index: IdxId) -> Result<Vec<Record>, String> {
        self.record_command(|r| r.dump_index_dynamic(index));
        Ok(self
            .dump_index(index)?
            .into_iter()
            .map(|v| v.into_record())
            .collect())
    }

    fn stop(&self) -> Result<(), String> {
        self.prog.lock().unwrap().stop()
    }
}

impl DDlog for HDDlog {
    fn transaction_commit_dump_changes(&self) -> Result<DeltaMap<DDValue>, String> {
        self.record_command(|r| r.transaction_commit_dump_changes());
        *self.deltadb.lock().unwrap() = Some(DeltaMap::new());

        self.update_handler.before_commit();
        match (self.prog.lock().unwrap().transaction_commit()) {
            Ok(()) => {
                self.update_handler.after_commit(true);
                let mut delta = self.deltadb.lock().unwrap();
                Ok(delta.take().unwrap())
            }
            Err(e) => {
                self.update_handler.after_commit(false);
                Err(e)
            }
        }
    }

    fn apply_updates(&self, upds: &mut dyn Iterator<Item = Update<DDValue>>) -> Result<(), String> {
        // Make sure that the updates being inserted have the correct value types for their
        // relation
        let inspect_update: fn(&Update<DDValue>) -> Result<(), String> = |update| {
            let relation = Relations::try_from(update.relid())
                .map_err(|_| format!("unknown relation id {}", update.relid()))?;

            if let Some(value) = update.get_value() {
                if relation.type_id() != value.type_id() {
                    return Err(format!("attempted to insert the incorrect type {:?} into relation {:?} whose value type is {:?}", value.type_id(), relation, relation.type_id()));
                }
            }

            Ok(())
        };

        if self.command_recorder.is_some() {
            let update_vec: Vec<_> = upds.collect();
            self.record_command(|r| r.apply_updates(&mut update_vec.iter().cloned()));

            self.prog
                .lock()
                .unwrap()
                .apply_updates(&mut update_vec.into_iter(), inspect_update)
        } else {
            self.prog
                .lock()
                .unwrap()
                .apply_updates(upds, inspect_update)
        }
    }

    fn query_index(&self, index: IdxId, key: DDValue) -> Result<BTreeSet<DDValue>, String> {
        self.record_command(|r| r.query_index(index, key.clone()));
        let idx = Indexes::try_from(index).map_err(|()| format!("unknown index {}", index))?;
        let arrid = indexes2arrid(idx);
        self.prog.lock().unwrap().query_arrangement(arrid, key)
    }

    fn dump_index(&self, index: IdxId) -> Result<BTreeSet<DDValue>, String> {
        self.record_command(|r| r.dump_index(index));
        let idx = Indexes::try_from(index).map_err(|()| format!("unknown index {}", index))?;
        let arrid = indexes2arrid(idx);
        self.prog.lock().unwrap().dump_arrangement(arrid)
    }
}

impl D3log for HDDlog {
    fn d3log_localize_val(
        &self,
        relid: RelId,
        val: DDValue,
    ) -> Result<(Option<D3logLocationId>, RelId, DDValue), DDValue> {
        d3log_localize_val(relid, val)
    }
}

/* Internals */
impl HDDlog {
    fn do_run(
        workers: usize,
        do_store: bool,
        print_err: Option<extern "C" fn(msg: *const raw::c_char)>,
    ) -> Result<(Self, DeltaMap<DDValue>), String> {
        let workers = if workers == 0 { 1 } else { workers };

        let db: Arc<Mutex<DeltaMap<DDValue>>> = Arc::new(Mutex::new(DeltaMap::new()));
        let db2 = db.clone();

        let deltadb: Arc<Mutex<Option<DeltaMap<_>>>> = Arc::new(Mutex::new(Some(DeltaMap::new())));
        let deltadb2 = deltadb.clone();

        let handler: Box<dyn IMTUpdateHandler> = {
            let handler_generator = move || {
                /* Always use delta handler, which costs nothing unless it is
                 * actually used. */
                let delta_handler = DeltaUpdateHandler::new(deltadb2);

                if do_store {
                    let handlers: Vec<Box<dyn UpdateHandler>> = vec![
                        Box::new(delta_handler),
                        Box::new(ValMapUpdateHandler::new(db2)),
                    ];
                    Box::new(ChainedUpdateHandler::new(handlers)) as Box<dyn UpdateHandler>
                } else {
                    Box::new(delta_handler) as Box<dyn UpdateHandler>
                }
            };
            Box::new(ThreadUpdateHandler::new(handler_generator))
        };

        let program = prog(handler.mt_update_cb());

        /* Notify handler about initial transaction */
        handler.before_commit();
        let prog = program.run(workers as usize)?;
        handler.after_commit(true);

        /* Extract state after initial transaction. */
        let init_state = deltadb.lock().unwrap().take().unwrap();

        Ok((
            HDDlog {
                prog: Mutex::new(prog),
                update_handler: handler,
                db: Some(db),
                deltadb,
                print_err,
                command_recorder: None,
            },
            init_state,
        ))
    }

    fn db_dump_table<F>(db: &mut DeltaMap<DDValue>, table: usize, cb: Option<F>)
    where
        F: Fn(&record::Record, isize) -> bool,
    {
        if let Some(f) = cb {
            for (val, w) in db.get_rel(table) {
                //assert!(*w == 1);
                if !f(&val.clone().into_record(), *w) {
                    break;
                }
            }
        };
    }

    fn record_command<T, F>(&self, cmd: F)
    where
        F: FnOnce(
            &CommandRecorder<fs::File, Box<dyn DDlogInventory + Send + Sync>>,
        ) -> Result<T, String>,
    {
        if let Some(ref r) = self.command_recorder {
            let _ = cmd(r).map_err(|e| {
                self.eprintln(&format!(
                    "failed to record invocation in replay file: {}",
                    e
                ));
            });
        }
    }
}

pub fn updcmd2upd(c: &record::UpdCmd) -> Result<Update<DDValue>, String> {
    match c {
        record::UpdCmd::Insert(rident, rec) => {
            let relid =
                Relations::try_from(rident).map_err(|_| format!("Unknown relation {}", rident))?;
            let val = relval_from_record(relid, rec)?;
            Ok(Update::Insert {
                relid: relid as RelId,
                v: val,
            })
        }
        record::UpdCmd::InsertOrUpdate(rident, rec) => {
            let relid =
                Relations::try_from(rident).map_err(|_| format!("Unknown relation {}", rident))?;
            let val = relval_from_record(relid, rec)?;
            Ok(Update::InsertOrUpdate {
                relid: relid as RelId,
                v: val,
            })
        }
        record::UpdCmd::Delete(rident, rec) => {
            let relid =
                Relations::try_from(rident).map_err(|()| format!("Unknown relation {}", rident))?;
            let val = relval_from_record(relid, rec)?;
            Ok(Update::DeleteValue {
                relid: relid as RelId,
                v: val,
            })
        }
        record::UpdCmd::DeleteKey(rident, rec) => {
            let relid =
                Relations::try_from(rident).map_err(|()| format!("Unknown relation {}", rident))?;
            let key = relkey_from_record(relid, rec)?;
            Ok(Update::DeleteKey {
                relid: relid as RelId,
                k: key,
            })
        }
        record::UpdCmd::Modify(rident, key, rec) => {
            let relid =
                Relations::try_from(rident).map_err(|()| format!("Unknown relation {}", rident))?;
            let key = relkey_from_record(relid, key)?;
            Ok(Update::Modify {
                relid: relid as RelId,
                k: key,
                m: Arc::new(rec.clone()),
            })
        }
    }
}
